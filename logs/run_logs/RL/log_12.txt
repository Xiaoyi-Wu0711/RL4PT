start_time  Thu Aug 31 15:38:13 2023
 Start training with total steps:  9000
Using cuda device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
------------------------------
 self.episode  0
seed value  380551
Logging to ./results/PPO_Thu Aug 31 15:38:13 2023/tensorboards/PPO/PPO_1
------------------------------
 self.episode  1
seed value  597416
------------------------------
 self.episode  2
seed value  712422
------------------------------
 self.episode  3
seed value  490110
------------------------------
 self.episode  4
seed value  801227
------------------------------
 self.episode  5
seed value  559187
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 328      |
| time/              |          |
|    fps             | 0        |
|    iterations      | 1        |
|    time_elapsed    | 2458     |
|    total_timesteps | 150      |
---------------------------------
------------------------------
 self.episode  6
seed value  899684
------------------------------
 self.episode  7
seed value  337899
------------------------------
 self.episode  8
seed value  948189
------------------------------
 self.episode  9
seed value  946209
------------------------------
 self.episode  10
seed value  855873
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 30           |
|    ep_rew_mean          | 329          |
| time/                   |              |
|    fps                  | 0            |
|    iterations           | 2            |
|    time_elapsed         | 4909         |
|    total_timesteps      | 300          |
| train/                  |              |
|    approx_kl            | 0.0025309385 |
|    clip_fraction        | 0.00883      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.000807     |
|    learning_rate        | 0.0001       |
|    loss                 | 8.29e+03     |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0143      |
|    std                  | 1            |
|    value_loss           | 1.76e+04     |
------------------------------------------
