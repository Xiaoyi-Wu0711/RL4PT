{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import random\n",
    "import os, time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import sleep\n",
    "import datetime\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import random\n",
    "import os, time\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from gym.spaces.box import Box\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import sleep\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "from gym import Env \n",
    "import gym\n",
    "#IMPORTS\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.env_util import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit, prange\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import random\n",
    "import os, time\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal, Categorical\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import sleep\n",
    "import datetime\n",
    "import argparse\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "import random\n",
    "import os, time\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from time import sleep\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, prange\n",
    "\n",
    "#IMPORTS\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO, DDPG, TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.env_util import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import VecNormalize, VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gymnasium.wrappers import NormalizeObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/xiaoyiwu/DTU/Project%201/git/RL4PT/examples\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: examples\n",
      "  Attempting uninstall: examples\n",
      "    Found existing installation: examples 0.0.1\n",
      "    Uninstalling examples-0.0.1:\n",
      "      Successfully uninstalled examples-0.0.1\n",
      "  Running setup.py develop for examples\n",
      "Successfully installed examples-0.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -e examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time  Fri Sep  1 12:49:51 2023\n",
      " learning_rate  0.01\n",
      " Start training with total steps:  6\n"
     ]
    },
    {
     "ename": "NamespaceNotFound",
     "evalue": "Namespace examples not found. Have you installed the proper package for examples?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNamespaceNotFound\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaoyiwu/DTU/Project 1/git/RL4PT/tmp.ipynb Cell 3\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(save_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m Start training with total steps: \u001b[39m\u001b[39m\"\u001b[39m, train_time_steps,)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mexamples/CommuteEnv-v0\u001b[39;49m\u001b[39m'\u001b[39;49m, simulation_day_num \u001b[39m=\u001b[39;49m simulation_day_num, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                 save_episode_freq \u001b[39m=\u001b[39;49m save_episode_train, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                 train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, save_dir \u001b[39m=\u001b[39;49m save_dir, space_shape\u001b[39m=\u001b[39;49m(\u001b[39m4\u001b[39;49m, \u001b[39mint\u001b[39;49m(\u001b[39m12\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m5\u001b[39;49m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m env \u001b[39m=\u001b[39m NormalizeObservation(env)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaoyiwu/DTU/Project%201/git/RL4PT/tmp.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m seed_value \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/gymnasium/envs/registration.py:740\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mid\u001b[39m, \u001b[39mstr\u001b[39m)\n\u001b[1;32m    739\u001b[0m     \u001b[39m# The environment name can include an unloaded module in \"module:env_name\" style\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     env_spec \u001b[39m=\u001b[39m _find_spec(\u001b[39mid\u001b[39;49m)\n\u001b[1;32m    742\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(env_spec, EnvSpec)\n\u001b[1;32m    744\u001b[0m \u001b[39m# Update the env spec kwargs with the `make` kwargs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/gymnasium/envs/registration.py:537\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(env_id)\u001b[0m\n\u001b[1;32m    531\u001b[0m     logger\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    532\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing the latest versioned environment `\u001b[39m\u001b[39m{\u001b[39;00mnew_env_id\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00menv_name\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m     )\n\u001b[1;32m    536\u001b[0m \u001b[39mif\u001b[39;00m env_spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     _check_version_exists(ns, name, version)\n\u001b[1;32m    538\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo registered env with id: \u001b[39m\u001b[39m{\u001b[39;00menv_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    540\u001b[0m \u001b[39mreturn\u001b[39;00m env_spec\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/gymnasium/envs/registration.py:403\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[39mif\u001b[39;00m get_env_id(ns, name, version) \u001b[39min\u001b[39;00m registry:\n\u001b[1;32m    401\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m _check_name_exists(ns, name)\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/gymnasium/envs/registration.py:366\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39m\"\"\"Check if an env exists in a namespace. If it doesn't, print a helpful error message.\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m# First check if the namespace exists\u001b[39;00m\n\u001b[0;32m--> 366\u001b[0m _check_namespace_exists(ns)\n\u001b[1;32m    368\u001b[0m \u001b[39m# Then check if the name exists\u001b[39;00m\n\u001b[1;32m    369\u001b[0m names: \u001b[39mset\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m {\n\u001b[1;32m    370\u001b[0m     env_spec\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m env_spec \u001b[39min\u001b[39;00m registry\u001b[39m.\u001b[39mvalues() \u001b[39mif\u001b[39;00m env_spec\u001b[39m.\u001b[39mnamespace \u001b[39m==\u001b[39m ns\n\u001b[1;32m    371\u001b[0m }\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/gymnasium/envs/registration.py:360\u001b[0m, in \u001b[0;36m_check_namespace_exists\u001b[0;34m(ns)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     suggestion_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHave you installed the proper package for \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 360\u001b[0m \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mNamespaceNotFound(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNamespace \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m not found. \u001b[39m\u001b[39m{\u001b[39;00msuggestion_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNamespaceNotFound\u001b[0m: Namespace examples not found. Have you installed the proper package for examples?"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"start_time \", time.asctime(time.localtime(start_time)))\n",
    "train = True\n",
    "test = True\n",
    "resume = False \n",
    "train_episode = 3\n",
    "simulation_day_num = 2 # the simulation days in one iteration \n",
    "train_time_steps = int(simulation_day_num * train_episode)# total train times\n",
    "evaluation_time_episode = 1 # evaluation times\n",
    "save_episode_train = 2 # the episode number to save train results\n",
    "save_episode_test = evaluation_time_episode \n",
    "learning_rate = 0.01\n",
    "print(\" learning_rate \", learning_rate)\n",
    "if train: \n",
    "    save_dir = \"./results/PPO_\"+time.asctime(time.localtime(start_time))\n",
    "    isExist = os.path.exists(save_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(save_dir)\n",
    "    print(\" Start training with total steps: \", train_time_steps,)\n",
    "    env = gym.make('examples/CommuteEnv-v0', simulation_day_num = simulation_day_num, \n",
    "                    save_episode_freq = save_episode_train, \n",
    "                    train=True, save_dir = save_dir, space_shape=(4, int(12*60/5)))\n",
    "    env = NormalizeObservation(env)\n",
    "    seed_value = 0\n",
    "    checkpoint_callback = CheckpointCallback(save_freq= int(save_episode_train*simulation_day_num), save_path=(save_dir+\"/logs/\"), name_prefix=\"PPO\")\n",
    "    if resume == True: \n",
    "        model = PPO.load((\"./results/PPO_Wed Aug 16 15:16:15 2023/logs/PPO_\"+str(900)+\"_steps\"), print_system_info=True, env=env)\n",
    "        model.learn(total_timesteps = train_time_steps, callback = checkpoint_callback, reset_num_timesteps=False, tb_log_name= \"second_run\")\n",
    "        model.save(save_dir+\"/logs/\"+str(900+train_time_steps)+\"_steps\")\n",
    "    else:\n",
    "        model = PPO(\"MlpPolicy\", env, learning_rate=learning_rate, n_steps=2, verbose=1, batch_size=2, \n",
    "                target_kl=0.05, n_epochs=10, gae_lambda=0.97, tensorboard_log=(save_dir+\"/tensorboards/PPO/\"))\n",
    "        model.learn(total_timesteps = train_time_steps, tb_log_name= \"first_run\", callback = checkpoint_callback)\n",
    "        model.save(save_dir+\"/logs/\"+str(train_time_steps)+\"_steps\")\n",
    "    # save_freq is the save frequency steps\n",
    "    print(\" \")\n",
    "    print(\"finish training!!!!!!!!!!!!!!!!!\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_env = NormalizeObservation(env)\n",
    "wrapper_env.observation_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper_env.step(action=[ 0.3344979 ,  0.05796875, -0.25174105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Function definition\n",
    "# Speed function\n",
    "ffspeed = 45\n",
    "capacity = 9000\n",
    "\n",
    "user_params = {'lambda': 3, 'gamma': 2,'hetero':1.6}\n",
    "scenario = 'Trinity' # simulate:'NT': no toll, 'CP': congestion price, 'Trinity'\n",
    "Tstep = 1 # discretization in one day \n",
    "deltaP = 0.05\n",
    "RBTD = 100\n",
    "Plot = False\n",
    "verbose = True\n",
    "# Policy: False, uniform, personalizedCap, personalizedNocap\n",
    "numOfusers = 7500\n",
    "toll = 'normal' # 'step', 'normal'\n",
    "marketPrice = 1 # initial market price\n",
    "iter = 0\n",
    "gamma = 0.02\n",
    "state_aggravate = 5\n",
    "\n",
    "#print('state_space',state_space)\n",
    "# only applies if scenario is CP\n",
    "if scenario == 'CP':\n",
    "     allowance = {'policy': 'personalization','ctrl':1.125,'cap':float(\"inf\")}\n",
    "else:\n",
    "     allowance = {'policy': False,'ctrl':1.048,'cap':float(\"inf\")}\n",
    "marketPrice = 1\n",
    "\n",
    "# only applies if scenario is Trinity\n",
    "if scenario == 'Trinity':\n",
    "     allocation = {'AR':0.00269,'way':'continuous','FTCs': 0.05,'FTCb':0.05,'PTCs': 0.00,'PTCb':0.00,\"Decaying\": False}\n",
    "else:\n",
    "     allocation = {'AR':0.0,'way':'lumpsum','FTCs': 0,'FTCb':0,'PTCs': 0,'PTCb':0,\"Decaying\":False}\n",
    "CV = False\n",
    "if scenario == 'NT':\n",
    "     CV = False\n",
    "#1.02557013 327.8359478  371.82177488\n",
    "unusual = {\"unusual\":False,'day':10,\n",
    "                \"read\":'Trinitytt.npy','ctrlprice':2.63,\n",
    "                'regulatesTime':415,'regulateeTime':557,\n",
    "          \"dropstime\":360,\"dropetime\":480,\"FTC\": 0.05,\"AR\":0.0}\n",
    "\n",
    "storeTT = {'flag':False,\"ttfilename\":'Trinitylumptt'}\n",
    "\n",
    "\n",
    "\n",
    "def gini(x):\n",
    "     # (Warning: This is a concise implementation, but it is O(n**2)\n",
    "     # in time and memory, where n = len(x).  *Don't* pass in huge\n",
    "     # samples!)\n",
    "\n",
    "     # Mean absolute difference\n",
    "     mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "     # Relative mean absolute difference\n",
    "     rmad = mad/np.mean(x)\n",
    "     # Gini scoefficient\n",
    "     g = 0.5 * rmad\n",
    "     return g\n",
    "\n",
    "@njit\n",
    "def V(x):\n",
    "     if isinstance(x, list):\n",
    "          return [np.square(1 - i / capacity) * ffspeed for i in x]\n",
    "     else:\n",
    "          return np.square(1 - x / capacity) * ffspeed\n",
    "\n",
    "# Event-based simulation, reffering to Algorithm 1 in the paper\n",
    "\n",
    "@njit\n",
    "def V1(x):\n",
    "     return np.square(1 - x / capacity) * ffspeed\n",
    "\n",
    "@njit(parallel=True)\n",
    "def estimated_TT(all_time_matrix,  time_list, car_number, _Accumulation, dist, ffspeed):\n",
    "    user_number = all_time_matrix.shape[0]\n",
    "    departure_steps = all_time_matrix.shape[1]\n",
    "    user_in_the_network = car_number\n",
    "    Accumulation = _Accumulation\n",
    "    new_time_ls = time_list # store everyone's last-day departure and arrival time as 1-d list\n",
    "    actual_TT_tmp = np.zeros((user_number, departure_steps)) # predict the travel time in each possible departure time\n",
    "    for user in prange(user_number):\n",
    "        for t in prange(departure_steps): \n",
    "            start_time = all_time_matrix[user, t]\n",
    "            known_ls = new_time_ls[new_time_ls > start_time]\n",
    "            if len(known_ls) == 0: # the fictional departure happens after all travelers\n",
    "                texp = dist/ffspeed * 60\n",
    "            elif len(known_ls) == user_in_the_network * 2:  # the fictional departure happens before all travelers\n",
    "                texp = 0\n",
    "                count = 0\n",
    "                left_len = dist- ffspeed /60 * (known_ls[0] - start_time) # compute the left trip length till the first real traveler enter \n",
    "                if left_len < 0: # this fictional traveler end his trip before the first real traveler enter the network\n",
    "                    texp =dist/ffspeed * 60\n",
    "                else: # compute the travel speed between 2 consecutive events\n",
    "                    V_list = np.array([V1(x) for x in Accumulation[user_in_the_network * 2 - len(known_ls): -1]])\n",
    "                    # print(\"known_ls.shape \", known_ls.shape)\n",
    "                    # print(\"V_list.shape \", V_list.shape)\n",
    "                    # trip length traveled in each time interval between two consecutive events\n",
    "                    len_piece = np.diff(known_ls) * V_list / 60\n",
    "                    cum_len = np.cumsum(len_piece)\n",
    "                    count = np.sum(cum_len < left_len)\n",
    "                    texp = known_ls[count + 1] - start_time  \\\n",
    "                            + (left_len - cum_len[count]) / V1(Accumulation[count]) * 60\n",
    "            else: # fictional departure happens after some real travelers have entered the network\n",
    "                texp = 0 \n",
    "                count = 0\n",
    "                # todo: change self.dist to trip_len\n",
    "                left_len = dist - V1(Accumulation[user_in_the_network * 2 - len(known_ls) - 1]) / 60 * (known_ls[0] - start_time) \n",
    "                if left_len < 0:  # if this fictional traveler end his trip before the next real event occurs\n",
    "                    texp = dist / V1(Accumulation[user_in_the_network * 2 - len(known_ls) - 1]) * 60\n",
    "                else:\n",
    "                    # travel speed in each time interval between two consecutive events\n",
    "                    V_list = np.array(\n",
    "                        [V1(x) for x in Accumulation[user_in_the_network * 2 - len(known_ls): -1]])\n",
    "                    len_piece = np.diff(known_ls) * V_list / 60\n",
    "                    cum_len = np.cumsum(len_piece)\n",
    "                    count = np.sum(cum_len < left_len)\n",
    "                    if count == 0:\n",
    "                        texp = known_ls[count] - start_time  \\\n",
    "                                + (left_len - (known_ls[count] - start_time) * V1(1)/60) / ffspeed * 60\n",
    "                    # this fictional traveler's is not finished even after all real\n",
    "                    # travelers finish their trips\n",
    "                    elif count == len(cum_len):\n",
    "                        texp = known_ls[count] - start_time + \\\n",
    "                            (left_len - cum_len[count - 1]) / ffspeed * 60\n",
    "                    else:  # this fictional traveler finishes the trip before all real travelers finish their trips\n",
    "                        texp = known_ls[count + 1] - start_time  \\\n",
    "                                + (left_len - cum_len[count]) / V1(Accumulation[user_in_the_network * 2 - len(known_ls) + count]) * 60\t\t\t\n",
    "            actual_TT_tmp[user, t] = texp\n",
    "    return actual_TT_tmp\n",
    "\n",
    "class Travelers():\n",
    "    # user parameters\n",
    "    # user accounts\n",
    "    # predicted departure times\n",
    "    # update trip intentions\n",
    "    # wihtin day mobility decisions\n",
    "    # sell and buy\n",
    "    # compute user account \n",
    "    # distance is asummed to be 16miles\n",
    "    def __init__(self,_numOfusers,_user_params,_allowance,_allocation,_scenario,_hoursInA_Day = 12,_Tstep = 1,\n",
    "                _fftt=24, _dist=18, _choiceInterval = 30, _seed=5843, _unusual=False,_CV=True,_numOfdays=50):\n",
    "\n",
    "        self.AR = _allocation['AR']\n",
    "        self.ARway = _allocation['way'] # It means that the allocation or distribution is made as a one-time, whole amount, rather than being spread out over a period of time or divided into smaller installments.\n",
    "        self.FTCs = _allocation['FTCs']\n",
    "        self.FTCb = _allocation['FTCb']\n",
    "        self.PTCs = _allocation['PTCs']\n",
    "        self.PTCb = _allocation['PTCb']\n",
    "        \n",
    "        self.users = np.arange(_numOfusers)\n",
    "        self.numOfusers = _numOfusers\n",
    "        self.hoursInA_Day = _hoursInA_Day\n",
    "        self.Tstep = _Tstep\n",
    "        self.fftt = _fftt # free flow travel time\n",
    "        self.dist = _dist\n",
    "        self.mpg = 23 \n",
    "        self.fuelprice = 4\n",
    "        self.ptfare = 2 # public transport fees\n",
    "        self.ptspeed = 25\n",
    "        self.pttt = self.dist/self.ptspeed*60 # public travel time in minutes\n",
    "        self.ffspeed = 45\n",
    "        self.ptheadway = 10\n",
    "\n",
    "        self.choiceInterval = _choiceInterval # departure interval h\n",
    "        self.user_params = _user_params\n",
    "        self.seed = _seed\n",
    "        self.allowance = _allowance\n",
    "        self.scenario = _scenario\n",
    "        self.unusual = _unusual\n",
    "        self.CV = _CV\n",
    "        self.numOfdays = _numOfdays\n",
    "        self.decaying = _allocation['Decaying']\n",
    "        if self.CV:\n",
    "            self.NT_sysutil = np.load(\"./output/MFD/NT/NT_sysutil.npy\")\n",
    "        self.userCV = np.zeros(self.numOfusers) # calculate the user's willingness to pay for the shared ride based on their cost variation (CV) measure.\n",
    "        \n",
    "        # initialize user accounts\n",
    "        self.userAccounts = np.zeros(self.numOfusers)+self.AR*self.hoursInA_Day*60\n",
    "        self.distribution = np.zeros(self.numOfusers) # modify the allowance distribution for each user based on the defined policy.\n",
    "\n",
    "    def interpolatePDT(self):\n",
    "        x = np.array([390, 405, 420, 435, 450, 465, 480, 495, 510, 525 ,540, 555], dtype=float)\n",
    "        # from https://link.springer.com/article/10.1007/s11116-016-9750-2\n",
    "        y = np.array([0.06, 0.09, 0.095, 0.098, 0.098, 0.11, 0.095, 0.085, 0.08, 0.07,0.059,0.061 ])\n",
    "        from scipy.interpolate import interp1d\n",
    "        f = interp1d(x, y)\n",
    "        return f\n",
    "\n",
    "    def generatePDT(self):\n",
    "        np.random.seed(seed=self.seed)\n",
    "        # rejection sampling\n",
    "        def batch_sample(function, num_samples, xmin=390, xmax=555, ymax=0.15, batch=1000):\n",
    "            samples = []\n",
    "            while len(samples) < num_samples:\n",
    "                x = np.random.uniform(low=xmin, high=xmax, size=batch)\n",
    "                y = np.random.uniform(low=0, high=ymax, size=batch)\n",
    "                samples += x[y < function(x)].tolist()\n",
    "            return samples[:num_samples]\n",
    "        f = self.interpolatePDT()\n",
    "        samps = batch_sample(f, self.numOfusers)\n",
    "        samps_array = np.array(samps).astype(int)\n",
    "        return samps_array\n",
    "    \n",
    "    # calculate the utility and make choice based on logit model\n",
    "    def calculate_utility(self, _x,_FW, _ps, _price, _pb, _day, _RR, _toll, _begin_time):\n",
    "        price = _price\n",
    "        x = _x\n",
    "        FW = _FW\n",
    "        ps = _ps\n",
    "        pb = _pb\n",
    "        toll = _toll\n",
    "        RR = _RR\n",
    "        day = _day\n",
    "        begin_time = _begin_time\n",
    "        for user in self.users:\n",
    "            possibleDepartureTimes = self.all_time_matrix[user, :]\n",
    "            depature_steps = len(possibleDepartureTimes)\n",
    "            vot = self.vot[user] # value of time\n",
    "            sde = self.sde[user] # sde constant\n",
    "            sdl = self.sdl[user] # sdl constant\n",
    "            vow = self.waiting[user] # value of waiting time\n",
    "            I = self.I[user]  # income\n",
    "            prev_allowance = self.distribution[user] # non-CP scenario allowance is 0\n",
    "            utileps = np.zeros(1+depature_steps) # utility of each alternative (choice) for a particular user. It is a numpy array that stores the utility values corresponding to different departure time alternatives.\n",
    "            utileps[0] = self.user_eps[user, -1] # add random term of no travel\n",
    "            # print(\" utileps \", utileps.shape)\n",
    "            # print(\"self.user_eps[user]\", self.user_eps[user].shape)\n",
    "            # print(\" self.user_eps[user, 0:-1] \", self.user_eps[user, 0:-1].shape)\n",
    "            utileps[1:] = self.user_eps[user, 0:-1] \n",
    "            \n",
    "            tautilde = np.zeros(1+depature_steps) # estimated travel time\n",
    "            tautilde[0] = self.pttt\n",
    "            tautilde[1:] =self.predictedTT[user, :] # TODO: D2D LEARNININGadd tt of no travel\n",
    "\n",
    "            Th = np.zeros(1+depature_steps) # token prices\n",
    "            Th[0] = self.ptfare\n",
    "            Th[1:] = toll[possibleDepartureTimes]\n",
    "\n",
    "            # if self.ARway == \"continuous\":\n",
    "            # \tpossibleAB = x[user, possibleDepartureTimes] #possible account balance\n",
    "        \n",
    "            Diff = self.predictedTT[user, :] + self.all_time_matrix[user, :] -  self.desiredArrival[user] \n",
    "            SD = np.zeros(1+depature_steps)\n",
    "            SD[1:] =  sde * Diff[:] * (1 - np.array(Diff[:] < 0)) - sdl * Diff[:] * np.array(Diff[:] < 0) # schedule delay cost\n",
    "\n",
    "            ASC = np.zeros(len(utileps)) # Alternative Specific Constant.\" It represents a constant term in a discrete choice model that captures the systematic factors affecting the utility of an alternative (choice)\n",
    "            W = np.zeros(1+depature_steps) # waiting time\n",
    "            W[0] = 1/2*self.ptheadway\n",
    "\n",
    "            sysutil_t = ASC + ( -2 * vot * tautilde - SD - 2*vow*W ) # for all day, double travel time but not sde and sdl\n",
    "            \n",
    "            ch = np.zeros(len(utileps))\t#the expected cost, equals to opportunity cost plus operation cosT\n",
    "            if self.scenario == 'Trinity':\n",
    "                if self.ARway == 'lumpsum':\n",
    "                    buy = np.maximum(Th-self.userAccounts[user], 0)*price\n",
    "                    sell = np.maximum(self.userAccounts[user] - Th, 0)*price\n",
    "                    ch[:] = buy-sell\n",
    "                    ch[0] = Th[0]-np.maximum(self.userAccounts[user], 0)*price\n",
    "                elif self.ARway == 'continuous':\n",
    "                    possibleAB = x[user, possibleDepartureTimes] #possible account balance\n",
    "                    # calculate opportunity cost\n",
    "                    tempTh = Th[1:] # exclude the first element corresponding to no travel\n",
    "                    if self.decaying:\n",
    "                        ch[1:] = -np.where(possibleAB>=tempTh, (FW-tempTh)*ps-(ps*self.AR*((FW-tempTh)/self.AR)**2/(2*self.hoursInA_Day*60))-self.FTCs,\n",
    "                                    np.maximum(-(tempTh-possibleAB)*pb-self.FTCb+(FW-possibleAB)*ps-(ps*self.AR*((FW-possibleAB)/self.AR)**2/(2*self.hoursInA_Day*60))-self.FTCs, 0))\n",
    "                        ch[0] = Th[0]-np.maximum((FW)*ps-(ps*self.AR*((FW)/self.AR)**2/(2*self.hoursInA_Day*60))-self.FTCs, 0)\n",
    "                    else:\n",
    "                        ch[1:] = -np.where(possibleAB>=tempTh, (FW-tempTh)*ps-self.FTCs , (FW-possibleAB)*ps-self.FTCs-((tempTh-possibleAB)*pb+self.FTCb))\n",
    "                        ch[0] = Th[0]-np.maximum((FW)*ps-self.FTCs,0)\t\t\t\n",
    "            else:\n",
    "                buy = Th*price\n",
    "                sell = np.zeros_like(Th)\n",
    "                ch = buy-sell-prev_allowance\n",
    "            ch[1:] += self.dist/self.mpg # add fuel price\n",
    "            ch = ch*2 # double for all day\n",
    "            ch_woallowance = (ch/2+prev_allowance)*2\n",
    "            \n",
    "            # allowance\n",
    "            if not self.allowance['policy']:\n",
    "                self.distribution[user] = 0\n",
    "            elif self.allowance['policy'] == 'uniform':\n",
    "                self.distribution[user] = RR/self.numOfusers\n",
    "            elif self.allowance['policy'] =='personalization':\n",
    "                income_c = self.user_params['lambda']*np.log(self.user_params['gamma']+I-ch_woallowance)\n",
    "                idx = np.argmax(sysutil_t+income_c-ch_woallowance+utileps)\n",
    "                if self.user_params['lambda']/(self.user_params['gamma']+I-ch_woallowance[idx])+1<=self.allowance['ctrl']:\n",
    "                    self.distribution[user] = 0\n",
    "                else:\n",
    "                    distribution = np.linspace(max(max(ch_woallowance-I),0),max(max(ch_woallowance-I),0)+30,num=300)\n",
    "                    a_idx = self.user_optimization(distribution, self.allowance['ctrl'],ch_woallowance, I,sysutil_t,user,utileps)\n",
    "                    self.distribution[user] = min(distribution[a_idx],self.allowance['cap'])\n",
    "\n",
    "            sysutil = (sysutil_t + self.user_params['lambda']*np.log(self.user_params['gamma'] + I-ch) + I-ch)\n",
    "            util = sysutil + utileps\n",
    "\n",
    "            if self.CV:\n",
    "                if day == self.numOfdays - 1:\n",
    "                    self.userCV[user] =  self.calculate_swcv(self.mu[user], [0], max(int(500/self.mu[user]), 500),\n",
    "                        len(possibleDepartureTimes)+1, self.NT_sysutil[user,:], sysutil_t, ch, self.I[user])\n",
    "                else:\n",
    "                    self.userCV[user] = 0\n",
    "    \n",
    "            if np.argmax(util) == 0: # choose no travel\n",
    "                self.ptshare.append(user)\n",
    "                self.predayDeparture[user] = -1\n",
    "            else:\n",
    "                departuretime = possibleDepartureTimes[np.argmax(util)-1] + begin_time\n",
    "                self.predayDeparture[user] = departuretime\n",
    "            self.predayEps[user] = utileps[np.argmax(util)]\n",
    "\n",
    "    # Generate travelers parameters (vot, sde, sdl, mu, epsilon, income)\n",
    "    # and trip intentions (desired arrival time, choice set)\n",
    "    def newvot(self,cov = 1.6):\n",
    "        np.random.seed(seed=self.seed)\n",
    "        if cov == 0.2:\n",
    "            newvot = np.random.lognormal(-2.2,0.2,self.numOfusers)\n",
    "        elif cov == 0.9:\n",
    "            newvot = np.random.lognormal(-2.2,0.78,self.numOfusers)\n",
    "        return newvot\n",
    "\n",
    "    def generate_params(self):\n",
    "        np.random.seed(seed=self.seed)\n",
    "        self.betant = 20\n",
    "        self.vot = np.exp(np.random.normal(5.104019892828459, 1.1311644092299618,self.numOfusers))/8/60/3 # value of time\n",
    "        annualincome = self.vot*3*60*8*260\n",
    "        if self.user_params['hetero'] != 1.6:\n",
    "            newvot = self.newvot(cov = self.user_params['hetero'])\n",
    "            self.vot[np.argsort(annualincome)] = newvot[np.argsort(newvot)]\n",
    "        ratiomu = np.random.triangular(0.1,0.5,1,self.numOfusers)\n",
    "        self.sde = self.vot*ratiomu #self.vot/np.exp(0.3)\n",
    "        ratioeta = np.random.triangular(1,2,3,self.numOfusers)\n",
    "        self.sdl = self.vot*ratioeta#self.vot*np.exp(0.7)\n",
    "        self.waiting = self.vot*3\n",
    "\n",
    "        # daily earned income\n",
    "        self.I = np.maximum((annualincome/260)-0.6*7.25*8,0.4*7.25*8)\n",
    "        # print(\"annual income ginit\",gini(annualincome),\"remaining I gini\",gini(self.I))\t\n",
    "        self.desiredArrival = self.generatePDT()+self.fftt\n",
    "        # generate predicted travel\n",
    "        if self.unusual['read'] and self.unusual['unusual']:\n",
    "            self.predictedTT = np.load(self.unusual['read'])\n",
    "            self.actualTT =  np.load(self.unusual['read'])\n",
    "        else:\n",
    "            self.predictedTT = np.zeros((self.numOfusers, 2 * self.choiceInterval + 1))\n",
    "            self.actualTT = np.zeros((self.numOfusers, 2 * self.choiceInterval + 1))\n",
    "            self.predictedTT[:]=self.fftt\n",
    "            self.actualTT [:]=self.fftt\n",
    "\n",
    "        self.desiredDeparture = self.desiredArrival-self.fftt # generate desired departure time: user_len 1-d array \n",
    "        self.DepartureLowerBD = self.desiredDeparture-self.choiceInterval\n",
    "        self.DepartureUpperBD = self.desiredDeparture+self.choiceInterval\n",
    "        \n",
    "        # MFD user initialization\n",
    "        all_time_slot = pd.DataFrame() #record all users' possible departure time\n",
    "        for i in range(2 * self.choiceInterval + 1):\n",
    "            all_time_slot['t' + str(i)] = self.desiredDeparture -  self.choiceInterval + i # user_len * (2*choiceInterval+1)\n",
    "        self.all_time_matrix = np.array(all_time_slot) \n",
    "        \n",
    "        # initialize predayDeparture:  store the chosen departure time for each user on the previous day.\n",
    "        self.predayDeparture = np.zeros(self.numOfusers, dtype=int) + self.desiredDeparture\n",
    "\n",
    "        self.mu = np.random.lognormal(-0.8, 0.47,self.numOfusers)# avg mu as 0.7, co.v as 0.5\n",
    "        self.mu = np.maximum(self.mu, 0.005)\n",
    "        self.user_eps = np.zeros((self.numOfusers, 2*self.choiceInterval+1+1)) # one extra for no travel\n",
    "        for i in range(self.numOfusers):\n",
    "            self.user_eps[i,:] = np.random.gumbel(-0.57721 / self.mu[i], 1.0 /self.mu[i], (2*self.choiceInterval+1)+1) # one extra for no travel\n",
    "        \n",
    "\n",
    "        # self.predayDeparture = np.array([1, 2, 3])\n",
    "\n",
    "    # Make preday choice according to attributes (travel time, schedule delay, toll)\n",
    "    # PT user: suppose all tw windows are taken by cars\n",
    "    # Car user: suppose N-1 tw windows with 1 real travel experience time \n",
    "    def update_choice_MFD(self, _toll, _price, _day, _RR, _begin_time):\n",
    "        self.ptshare = [] # add user who take bus\n",
    "        self.bindingI = []\n",
    "        self.predayEps = np.zeros(self.numOfusers) # stores the utility values corresponding to the chosen departure time alternative for each user in the pre-day choice\n",
    "        self.numOfbindingI = 0\n",
    "        toll = _toll\n",
    "        price = _price\n",
    "        day = _day\n",
    "        RR = _RR\n",
    "        begin_time = _begin_time\n",
    "        pb = price*(1+self.PTCb) # selling price\n",
    "        ps = price*(1-self.PTCs) # buying price\n",
    "\n",
    "        # MFD simulation attributes\n",
    "        # TODO: change heterogenous trip length\n",
    "        trip_len = np.zeros(self.numOfusers)\n",
    "        trip_len[:] = self.dist\n",
    "\n",
    "        if day != 0: # if it is not the first day, make choice based on history; else depart at desired departure time\n",
    "            _toll = np.mean(np.array(_toll).reshape(-1, self.Tstep), axis=1)  # get the toll for each Tstep\n",
    "            x = np.zeros((self.numOfusers, self.hoursInA_Day*60)) # token account balance\n",
    "            FW = 0\n",
    "            if self.ARway == 'continuous':\n",
    "                # predict today's account balances\n",
    "                FW = self.AR*self.hoursInA_Day*60 # full wallet\n",
    "                x[:, 0] = self.userAccounts # equals to initial token balance\n",
    "                td = np.where(self.predayDeparture !=-1, np.mod(self.predayDeparture, self.hoursInA_Day*60), -self.hoursInA_Day*60)\n",
    "                Td = np.where(td != -self.hoursInA_Day*60, _toll[td-td%self.Tstep], td) # toll fees\n",
    "                for t in range(self.hoursInA_Day*60-1): # calculate the profit at time t\n",
    "                    td = np.where(td != -self.hoursInA_Day*60, np.where(td<t, td+self.hoursInA_Day*60, td), td) \n",
    "                    profitAtT = np.zeros(self.numOfusers) #user profit at time t\n",
    "                    mask_cansell = td!=t\n",
    "                    FA = np.where(td!=-self.hoursInA_Day*60, np.minimum((td-t)*self.AR, FW), 0)\n",
    "                    if self.decaying:\n",
    "                        profitAtT = x[:, t]*ps-(ps*(x[:, t])**2/(2*self.hoursInA_Day*60*self.AR))-self.FTCs-np.where(Td>FA,(Td-FA)*pb+self.FTCb,0)\n",
    "                    else:\n",
    "                        profitAtT = x[:, t]*ps-self.FTCs-np.where(Td>FA,(Td-FA)*pb+self.FTCb,0)\n",
    "                    profitAtT[~mask_cansell] = 0.0\n",
    "                    mask_positiveprofit = profitAtT>1e-10\n",
    "                    mask_needbuy = Td>=FA\n",
    "                    mask_needbuynext = Td>=np.maximum(FA-self.AR, 0)\n",
    "                    mask_FW = np.abs(x[:, t]-FW)<1e-10\n",
    "                    mask_sellnow = (mask_cansell & mask_positiveprofit) & (mask_needbuy | mask_FW | mask_needbuynext)\n",
    "                    x[mask_sellnow, t] = 0\n",
    "                    x[:, t+1] = np.maximum(FW, x[:, t]+self.AR)\n",
    "            self.calculate_utility(x, FW, ps, price, pb, day, RR, toll, begin_time)\n",
    "    # end of update_choice_MFD\n",
    "\n",
    "    def update_TC(self,FTCs,FTCb,PTCs,PTCb):\n",
    "        self.FTCs = FTCs\n",
    "        self.FTCb = FTCb\n",
    "        self.PTCs = PTCs\n",
    "        self.PTCb = PTCb\n",
    "\n",
    "    def user_optimization(self,distribution, x,Th, I,sys_util_t,user,utileps):\n",
    "        # Th is the product of toll and price\n",
    "        # calculate logsum, which is slow\n",
    "        numOfdist = len(distribution)\n",
    "        numOfcost = len(Th)\n",
    "        a_exp = 2 * np.repeat(distribution,numOfcost).reshape(numOfdist,numOfcost)\n",
    "        # cost is positive\n",
    "        cost = np.tile(Th,(numOfdist,1))\n",
    "        income_c = self.user_params['lambda']*np.log(self.user_params['gamma'] + I - cost + a_exp)\n",
    "        sys_util_c = -cost + income_c + a_exp\n",
    "        sys_util = sys_util_t + sys_util_c\n",
    "        util = sys_util + utileps\n",
    "        idx = np.argmax(util,axis=1)\n",
    "        MUI = 1 + self.user_params['lambda']/(self.user_params['gamma'] + I-Th[idx] + distribution)\n",
    "        a_index = (np.abs(MUI - x)).argmin()\n",
    "        # obj = 1/self.mu[user]*np.log(np.sum(np.exp(self.mu[user]*sys_util),axis=1))-x*distribution\n",
    "        # a_index = np.argmax(obj)\n",
    "        return a_index\n",
    "    \n",
    "    \n",
    "    def get_numOfbindingI(self):\n",
    "        return self.numOfbindingI\n",
    "\n",
    "    # realize selling and buying behavior\n",
    "    def sell_and_buy(self, _t, _currToll, _toll, _price, _totTime):\n",
    "\n",
    "        FW = self.hoursInA_Day*60*self.AR\n",
    "        userBuy = np.zeros_like(self.userAccounts)\n",
    "        userSell = np.zeros_like(userBuy)\n",
    "        p = _price\n",
    "        departureTime  = self.predayDeparture.copy()\n",
    "        mask_cansell = np.where(departureTime!=-1, departureTime!=_t, True)\n",
    "        departureTime = np.where(departureTime!=-1, np.where(departureTime<_t, departureTime + self.hoursInA_Day * 60, departureTime), departureTime)\n",
    "\n",
    "        if self.ARway == 'lumpsum':\n",
    "            userBuy[~mask_cansell] = np.maximum((_currToll - self.userAccounts)[~mask_cansell],0)\n",
    "            # no need to calculate profit if allocation is lump-sum\n",
    "            # as selling will be automated at the end of day\n",
    "            mask_sellnow = False\n",
    "            if _t == _totTime-1:\n",
    "                mask_sellnow = (mask_cansell&(self.userAccounts>0))\n",
    "                userSell[mask_sellnow] = self.userAccounts[mask_sellnow]\n",
    "            # update user accounts for lump-sum allocation\n",
    "            # lump-sum allocation \n",
    "            mask_donothing = ~(mask_sellnow | ~mask_cansell)\n",
    "            self.userAccounts[mask_sellnow] = 0\n",
    "            self.userAccounts[~mask_cansell] = np.maximum((self.userAccounts-_currToll)[~mask_cansell], 0)\n",
    "            #self.userAccounts[mask_donothing] = np.maximum(self.userAccounts[mask_donothing]+AR,FW)\n",
    "            if _t == _totTime-1:\n",
    "                self.userAccounts[:] = FW\n",
    "\n",
    "        elif self.ARway == 'continuous':\n",
    "            # get buying tokens\n",
    "            userBuy[~mask_cansell] = np.where(_currToll>self.userAccounts[~mask_cansell], _currToll-self.userAccounts[~mask_cansell], 0.0)\n",
    "\n",
    "            FA = np.where(departureTime!=-1, np.minimum((departureTime-_t)*self.AR,FW),0)\n",
    "            B = np.where(departureTime!=-1,(_toll[np.mod(departureTime,self.hoursInA_Day*60)]-FA), departureTime)\n",
    "\n",
    "            if self.decaying:\n",
    "                S = self.userAccounts*p*(1-self.PTCs)-(p*(1-self.PTCs)*self.AR*(self.userAccounts/self.AR)**2/(2*self.hoursInA_Day*60))-self.FTCs\n",
    "            else:\n",
    "                S = self.userAccounts*p*(1-self.PTCs)-self.FTCs\n",
    "\n",
    "            profit = S-np.where(B>0, B*p*(1+self.PTCb)+self.FTCb, 0)\n",
    "\n",
    "            mask_positiveprofit = profit>1e-10\n",
    "            mask_needbuy = B>=0\n",
    "            mask_needbuynext = (B+self.AR)>0\n",
    "            mask_FW = np.abs(self.userAccounts-FW)<1e-10\n",
    "            mask_sellnow = (mask_cansell & mask_positiveprofit ) & (mask_needbuy | mask_FW | mask_needbuynext)\n",
    "            userSell[mask_sellnow] = self.userAccounts[mask_sellnow]\n",
    "\n",
    "            #### update accounts\n",
    "            currTime = np.mod(_t, self.hoursInA_Day*60) # range from 0 to hoursInA_Day*60\n",
    "            # handle selling\n",
    "            self.userAccounts[mask_sellnow] = self.AR # sell all and get new allocation\n",
    "\n",
    "            # handle paying toll and buying\n",
    "            self.userAccounts[~mask_cansell] = np.maximum((self.userAccounts-_currToll)[~mask_cansell],0)\n",
    "            self.userAccounts[~mask_cansell] = np.minimum(self.userAccounts[~mask_cansell]+self.AR,FW) # add new allocation and cap it at FW\n",
    "            # handle do nothing (expire oldest tokens if reach maximum life time and get new allocation)\n",
    "            mask_donothing = ~(mask_sellnow | ~mask_cansell)\n",
    "            self.userAccounts[mask_donothing] = np.minimum(self.userAccounts[mask_donothing]+self.AR,FW)\n",
    "            \n",
    "        return [userBuy, userSell]\n",
    "    \n",
    "    # compute future user accounts:\n",
    "    def update_account(self):\n",
    "        return\n",
    "\n",
    "    # actual arrival is the combination of estimated arrival(if he didn't those time points) \n",
    "    # and real arrival time(if he chooses this time point)\n",
    "    def update_arrival(self, actualArrival):\n",
    "        self.actualArrival = actualArrival\n",
    "\n",
    "        \n",
    "    # perform day to day learning\n",
    "    def d2d(self):\n",
    "        self.predictedTT = 0.9*self.predictedTT + 0.1*self.actualTT \n",
    "\n",
    "\n",
    "class Regulator():\n",
    "    # regulator account balance\n",
    "    def __init__(self, marketPrice=1, RBTD = 100, deltaP = 0.05):\n",
    "        self.RR = 0\n",
    "        self.tollCollected = 0\n",
    "        self.allowanceDistributed = 0\n",
    "        self.marketPrice = marketPrice\n",
    "        self.RBTD = 100  # a constant threshold\n",
    "        self.deltaP = 0.05\n",
    "\n",
    "    # update regulator account\n",
    "    def update_balance(self,userToll,userReceive):\n",
    "        # userToll: regulator revenue\n",
    "        # userReceive: regulator cost\n",
    "        self.tollCollected = np.sum(userToll)\n",
    "        self.allowanceDistributed = np.sum(userReceive)\n",
    "        self.RR = self.tollCollected - self.allowanceDistributed\n",
    "    \n",
    "    # update token price\n",
    "    def update_price(self):\n",
    "        if self.RR > self.RBTD:\n",
    "            self.marketPrice += self.deltaP\n",
    "        elif self.RR < -self.RBTD:\n",
    "            self.marketPrice -= self.deltaP\n",
    "\n",
    "\n",
    "class Simulation():\n",
    "    # simulate one day\n",
    "\n",
    "    def __init__(self,\n",
    "                  _user_params,_allocation ,_scenario='NT',_allowance=False,\n",
    "                  _numOfdays=30,_numOfusers=7500,_Tstep=1,_hoursInA_Day=12,_fftt=24,\n",
    "                _marketPrice = 1,_RBTD = 100, _deltaP=0.05,_Plot = False, _seed=5843,\n",
    "                _verbose = False,_unusual=False,_storeTT=False,_CV=True,save_dfname='CPresult.csv',\n",
    "                ):\n",
    "        self.numOfdays = _numOfdays\n",
    "        self.hoursInA_Day = _hoursInA_Day\n",
    "        self.numOfusers = _numOfusers\n",
    "        self.allowance = _allowance\n",
    "        self.save_dfname = save_dfname\n",
    "        self.currday = 0\n",
    "        self.fftt = _fftt\n",
    "        self.user_params = _user_params\n",
    "        self.Tstep = _Tstep\n",
    "        self.scenario = _scenario\n",
    "        self.FTCs = _allocation['FTCs']\n",
    "        self.FTCb = _allocation['FTCb']\n",
    "        self.PTCs = _allocation['PTCs']\n",
    "        self.PTCb = _allocation['PTCb']\n",
    "        self.Plot = _Plot\n",
    "        self.verbose = _verbose\n",
    "        self.unusual = _unusual\n",
    "        self.storeTT = _storeTT\n",
    "        self.CV = _CV\n",
    "        self.AR = _allocation['AR']\n",
    "        self.decaying = _allocation['Decaying']\n",
    "        self.tradedf = pd.DataFrame({'buy': np.zeros(self.hoursInA_Day*60),'sell': np.zeros(self.hoursInA_Day*60)})\n",
    "        self.flowdf = pd.DataFrame({'departure':np.zeros(self.numOfdays*self.numOfusers),'arrival':np.zeros(self.numOfdays*self.numOfusers),\n",
    "            'user':np.tile(np.arange(self.numOfusers),self.numOfdays)})\n",
    "        self.usertradedf = pd.DataFrame({'buy': np.zeros(self.hoursInA_Day*60),'sell': np.zeros(self.hoursInA_Day*60)}) # record user amount of trade behaviors\n",
    "        self.tokentradedf = pd.DataFrame({'buy': np.zeros(self.hoursInA_Day*60),'sell': np.zeros(self.hoursInA_Day*60)}) # record average token amount of trade behaviors\n",
    "\n",
    "        self.users = Travelers(self.numOfusers,_user_params=self.user_params,_allocation=_allocation,\n",
    "                             _fftt=_fftt, _hoursInA_Day=_hoursInA_Day,_Tstep=self.Tstep,\n",
    "                            _allowance=self.allowance, _scenario = self.scenario, _seed=_seed, \n",
    "                            _unusual=self.unusual, _CV = _CV,_numOfdays = _numOfdays)\n",
    "        self.users.generate_params()\n",
    "\n",
    "        self.regulator = Regulator(_marketPrice,_RBTD,_deltaP)\n",
    "        self.pricevec = [] # daily market price record\n",
    "        self.swvec = [] # daily social welfare record\n",
    "        self.flowconvergevec = [] \n",
    "        self.ptsharevec = []# daily PT sharing record\n",
    "        self.originalAtt = {}\n",
    "        self.presellAfterdep = np.zeros(self.numOfusers,dtype=int)\n",
    "        \n",
    "        \n",
    "    # If x is greater than or equal to x_step1 and less than x_step2, the toll is step1\n",
    "    def steptoll_fxn(self, x, step1=3, step2=6, step3=10, step4=6, step5=3, \n",
    "                      x_step1 = 250, x_step2 = 310, x_step3=360, x_step4=460, \n",
    "                    x_step5=510, x_step6=570):\n",
    "        steptoll = (x>=x_step1)*(x<x_step2)*step1 + (x>=x_step2)*(x<x_step3)*step2 + (x>=x_step3)*(x<x_step4)*step3 + \\\n",
    "            (x>=x_step4)*(x<x_step5)*step4 + (x>=x_step5)*(x<x_step6)*step5 + (x>=x_step6)*(x<x_step1)*0\n",
    "        return steptoll\n",
    "\n",
    "    #get the toll fee\n",
    "    def RL_bimodal(self, x, tollparameters):\n",
    "        # print(action)\n",
    "        mu = tollparameters[0]# 300, 540\n",
    "        sigma = tollparameters[1] # 50, 70\n",
    "        A = tollparameters[2]# 1,5\n",
    "        return A*np.exp(-(x-mu)**2/2/sigma**2)\n",
    "\n",
    "    # MFD simulation\n",
    "    def MFD(self, day):\n",
    "        # MFD simulation attributes\n",
    "        trip_len = np.zeros(self.numOfusers)\n",
    "        trip_len[:] = self.users.dist\n",
    "\n",
    "        # create a dict to store the information of each agent\n",
    "        vehicle_information = {}\n",
    "        vehicle_information['vehicle'] = np.arange(self.numOfusers)\n",
    "        vehicle_information['trip_len(m)'] =trip_len[:].astype(np.float64) #left length\n",
    "        vehicle_information['t_exp'] = np.zeros(self.numOfusers) # experienced time\n",
    "        vehicle_information['account'] = np.zeros(self.numOfusers) \n",
    "\n",
    "        t_ls = []  # record the event time which has not been removed\n",
    "        Accumulation = [] # event based accumulation record\n",
    "\n",
    "        n = 0  # Number of vehicle (accumulation)\n",
    "        j = 0  # index of event\n",
    "        vehicle_index = [] # vehicle in the event\n",
    "        Departure_time  = self.users.predayDeparture # departure time\n",
    "        Arrival_time  = np.where(Departure_time > 0, Departure_time+self.fftt, -1)\n",
    "    \n",
    "        # find the car users\n",
    "        car_index = np.where(Departure_time>0)[0]\n",
    "        pt_index = np.where(Departure_time<0)[0]\n",
    "        car_number = car_index.shape[0]\n",
    "        pt_number = pt_index.shape[0]\n",
    "\n",
    "        # Define event list of departures\n",
    "        Event_list1_array = np.zeros((car_number, 4))\n",
    "        Event_list1_array[:, 0] = car_index\n",
    "        Event_list1_array[:, 1] = Departure_time[car_index] \n",
    "        Event_list1_array[:, 2] = np.ones(car_number) \n",
    "        Event_list1_array[:, 3] = trip_len[car_index]\n",
    "\n",
    "        # Define event list of arrivals\n",
    "        Event_list2_array =  np.zeros((car_number, 4))\n",
    "        Event_list2_array[:, 0] = car_index\n",
    "        Event_list2_array[:, 1] = Arrival_time[car_index]   # time(min)\n",
    "        Event_list2_array[:, 2] = np.ones(car_number) * 2  # arrival indicator: 2\n",
    "        Event_list2_array[:, 3] = trip_len[car_index]  # trip length\n",
    "                \n",
    "        # S_Event_list_array: 4 columns\n",
    "        # vehicle_index  time(min)  event_indicator  trip_len\n",
    "        S_Event_list_array = np.concatenate(\n",
    "            (Event_list1_array, Event_list2_array), axis=0)\n",
    "        # print(\" day \", day)\n",
    "        # Sort the list by time in ascending order\n",
    "        S_Event_list_array = S_Event_list_array[S_Event_list_array[:, 1].argsort()]\n",
    "        # print(\"initial states \", S_Event_list_array)\n",
    "        # print(\"S_Event_list_array.shape \", S_Event_list_array.shape)\n",
    "        # get time of the first event\n",
    "        t_ls.append(S_Event_list_array[0, 1])  # initial time\n",
    "\n",
    "        while S_Event_list_array.shape[0] > 0: \n",
    "            j = j + 1\n",
    "            t_ls.append(S_Event_list_array[0, 1])\n",
    "            Event_index = int(S_Event_list_array[0, 0])\n",
    "            Event_type =  int(S_Event_list_array[0, 2])\n",
    "            # print(\"j \", j)\n",
    "            if Event_type == 1: # if it is departure event\n",
    "                \n",
    "                # add the vehicle index which has entered the network \n",
    "                vehicle_index.append(Event_index)\n",
    "\n",
    "                # update the left trip length for cars which have departured before \n",
    "                trip_len1 = vehicle_information['trip_len(m)']\n",
    "                trip_len1[vehicle_index[0:-1]] = trip_len1[vehicle_index[0:-1]] - V(n) / 60 * (t_ls[j] - t_ls[j - 1])\n",
    "                vehicle_information['trip_len(m)'] = trip_len1\n",
    "        \n",
    "                # update the accumulation in the network\n",
    "                n = n + 1\n",
    "                \n",
    "                # keep track of the accumulation\n",
    "                Accumulation.append(n)\n",
    "\n",
    "                # update the predicted arrival time for all cars which has entered the network\n",
    "                travel_started_vehicles = np.where((S_Event_list_array[:, 2] == 2) & \n",
    "                                                (np.isin(S_Event_list_array[:, 0], vehicle_index)))\n",
    "                temp = S_Event_list_array[(travel_started_vehicles)][:, 0] # get the vehicle index where the travel has been started\n",
    "                if np.size(temp) == 0:\n",
    "                    temp = np.array([])\n",
    "                S_Event_list_array[(travel_started_vehicles), 1] \\\n",
    "                    = t_ls[j] + vehicle_information['trip_len(m)'][temp.astype(int)] / V(n) * 60 \n",
    "\n",
    "            else: # if it is an arrival event\n",
    "                # update the trip lenth which has entered the network \n",
    "                trip_len1 = vehicle_information['trip_len(m)']\n",
    "                trip_len1[vehicle_index] = trip_len1[vehicle_index] - V(n) / 60 * (t_ls[j] - t_ls[j - 1]) \n",
    "                vehicle_information['trip_len(m)'] = trip_len1\n",
    "                # print(\"arrival\")\n",
    "                # print(\"left length \", trip_len1)\n",
    "                # print(\"\\n\")\n",
    "                n = n-1 \n",
    "\n",
    "                # keep track of the accumulation\n",
    "                Accumulation.append(n)\n",
    "\n",
    "                # update t_exp\n",
    "                vehicle_information['t_exp'][Event_index]\\\n",
    "                    = S_Event_list_array[0, 1] - Departure_time[Event_index] # actual experienced travel time\n",
    "\n",
    "                # remove the agent that finishes the trip\n",
    "                vehicle_index.remove(Event_index)\n",
    "\n",
    "                # Update the predicted arrival time\n",
    "                travel_started_vehicles = np.where((S_Event_list_array[:, 2] == 2) & (\n",
    "                    np.isin(S_Event_list_array[:, 0], vehicle_index)))\n",
    "                temp = S_Event_list_array[(travel_started_vehicles)][:, 0]\n",
    "                if np.size(temp) == 0:\n",
    "                    temp = np.array([])\n",
    "                S_Event_list_array[(travel_started_vehicles), 1]\\\n",
    "                    = t_ls[j] + vehicle_information['trip_len(m)'][temp.astype(int)] / V(n) * 60\n",
    "\n",
    "            # remove event from the list\n",
    "            S_Event_list_array = np.delete(S_Event_list_array, (0), axis=0)\n",
    "            S_Event_list_array = S_Event_list_array[S_Event_list_array[:, 1].argsort()]           \n",
    "\n",
    "        vehicle_information['t_dep'] = Departure_time[:]\n",
    "        vehicle_information['t_arr'] = np.where(vehicle_information[\"t_dep\"]> 0, vehicle_information[\"t_dep\"] + vehicle_information['t_exp'], -1)\n",
    "        # we exclude PT from the tt calculation: vehicle_information['t_exp'] = np.where(vehicle_information[\"t_dep\"]> 0, vehicle_information['t_exp'], self.users.pttt)\n",
    "        vehicle_information['t_exp'] = np.where(vehicle_information[\"t_dep\"]> 0, vehicle_information['t_exp'], self.users.pttt)\n",
    "\n",
    "\n",
    "        time_list = np.concatenate((\n",
    "            vehicle_information['t_dep'],\n",
    "            vehicle_information['t_arr']), \n",
    "            axis=0)\n",
    "        time_list_2 = time_list[np.where(time_list>0)]-(day)*720\n",
    "        time_list_2 = np.sort(time_list_2, axis=None)\n",
    "        \n",
    "        actual_TT_tmp = estimated_TT(self.users.all_time_matrix, time_list_2, car_number, Accumulation, self.users.dist, self.users.ffspeed)\n",
    "        self.users.actualTT[:] =  actual_TT_tmp[:]\n",
    "\n",
    "        return vehicle_information, time_list_2, Accumulation\n",
    "        # end of MFD\n",
    "\n",
    "    def RL_simulateOneday(self, tollparameters, day, state_aggravate):\n",
    "        timeofday = np.arange(self.hoursInA_Day*60) # the toll fees of the day\n",
    "        self.toll = np.repeat(np.maximum(self.RL_bimodal(timeofday[np.arange(0, self.hoursInA_Day*60, self.Tstep)], tollparameters),0),self.Tstep)\n",
    "        self.toll = np.around(self.toll, 2)\n",
    "        self.currday = day\n",
    "        # print(\" self.currday \" , self.currday)\n",
    "        beginTime = day*self.hoursInA_Day*60\n",
    "        totTime =  (day+1)*self.hoursInA_Day*60\n",
    "        self.users.update_choice_MFD(self.toll, self.regulator.marketPrice, \n",
    "                                       self.currday, self.regulator.tollCollected, beginTime)\n",
    "        self.numOfundesiredTrading = np.zeros(self.numOfusers)\n",
    "        sellTime = np.zeros(self.numOfusers)\n",
    "         \n",
    "        actualArrival = np.zeros(self.numOfusers) # traveler's arrival time\n",
    "        userSell = np.zeros(self.numOfusers) # user who sell tokens\n",
    "        userBuy = np.zeros(self.numOfusers) \n",
    "        userBuytc = np.zeros(self.numOfusers) # sell amount\n",
    "        userSelltc = np.zeros(self.numOfusers)\n",
    "        userToll = np.zeros(self.numOfusers)\n",
    "\n",
    "        buyvec = np.zeros(totTime-beginTime)\n",
    "        sellvec = np.zeros(totTime-beginTime)\n",
    "        buyamount = np.zeros(totTime-beginTime) # average buy token amount\n",
    "        sellamount = np.zeros(totTime-beginTime) # average sell token amount\n",
    "\n",
    "        average_tt = np.zeros(totTime-beginTime)\n",
    "        average_accumulation = np.zeros(totTime-beginTime)\n",
    "\n",
    "        if self.unusual['unusual'] and self.currday == self.unusual['day']:\n",
    "            self.originalAtt['price'] = self.regulator.marketPrice\n",
    "            self.originalAtt['FTCb'] = self.users.FTCb\n",
    "            self.originalAtt['FTCs'] = self.users.FTCs\n",
    "            self.originalAtt['PTCb'] = self.users.PTCb\n",
    "            self.originalAtt['PTCs'] = self.users.PTCs\n",
    "            self.originalAtt['AR'] = self.users.AR\n",
    "\n",
    "        vehicle_information, time_list, Accumulation = self.MFD(day)\t\t\n",
    "        actualArrival = vehicle_information[\"t_arr\"] #update actual travel time\n",
    "        travel_time =  vehicle_information[\"t_exp\"] # daily travel time without PT\n",
    "        Accumulation = np.array(Accumulation)\n",
    "\n",
    "        for t in range(beginTime, totTime):\n",
    "            tmp = np.mod(t-t%self.Tstep, self.hoursInA_Day*60)\n",
    "            currToll = self.toll[tmp]\n",
    "            start_t = tmp\n",
    "            finish_t = tmp + self.Tstep \n",
    "            current_event_index = np.where((time_list>=start_t) & (time_list<finish_t))\n",
    "            \n",
    "            if np.any(current_event_index[0]) :\n",
    "                mean_acc = np.mean(Accumulation[current_event_index]) # get the average mean accumulation in this time interval\n",
    "            else :\n",
    "                mean_acc = 0 \n",
    "            average_accumulation[tmp] = mean_acc\n",
    "\n",
    "            departure_time = vehicle_information[\"t_dep\"] - day*720\n",
    "            travel_time = vehicle_information[\"t_exp\"]\n",
    "            # has filtered pt transit\n",
    "            departured_car_index = np.where((departure_time>=start_t) & (departure_time<finish_t))\n",
    "            if np.any(departured_car_index[0]) :\n",
    "                mean_travel_time = np.mean(travel_time[departured_car_index])# get the average mean accumulation in this time interval\n",
    "            else :\n",
    "                mean_travel_time = 0 \n",
    "            average_tt[tmp] = mean_travel_time # get the average mean travel time\n",
    " \n",
    "            if self.scenario == 'Trinity':\n",
    "                tempuserBuy, tempuserSell = self.users.sell_and_buy(t, currToll, self.toll,self.regulator.marketPrice, totTime)\n",
    "                buy_user_amount= int(np.count_nonzero(tempuserBuy))\n",
    "                sell_user_amount= int(np.count_nonzero(tempuserSell))\n",
    "                buyvec[t-beginTime] = buy_user_amount\n",
    "                sellvec[t-beginTime] = sell_user_amount\n",
    "                if buy_user_amount != 0:\n",
    "                    buyamount[t-beginTime] = np.sum(tempuserBuy*self.regulator.marketPrice)/buy_user_amount\n",
    "                if sell_user_amount != 0:\n",
    "                    sellamount[t-beginTime] = np.sum(tempuserSell*self.regulator.marketPrice)/sell_user_amount\n",
    "\n",
    "                self.numOfundesiredTrading = np.where(((userSell >1e-6)|(self.presellAfterdep)) & (tempuserBuy>1e-6), 1, self.numOfundesiredTrading)\n",
    "                sellTime[np.where(tempuserSell>1e-6)[0]] = t\n",
    "                # userBuy += np.where(tempuserBuy>1e-6 ,tempuserBuy*self.regulator.marketPrice*(1+self.PTCb)+self.FTCb,0)\n",
    "                userBuy += np.where(tempuserBuy>1e-6, tempuserBuy*self.regulator.marketPrice*1, 0)\n",
    "                userBuytc += np.where(tempuserBuy>1e-6, tempuserBuy*self.regulator.marketPrice*self.PTCb+self.FTCb, 0)\n",
    "                if self.decaying:\n",
    "                    userSell += np.where(tempuserSell>1e-6,tempuserSell*self.regulator.marketPrice*(1)-\n",
    "                                                            (self.regulator.marketPrice*(1)*self.AR*(tempuserSell/self.AR)**2/(2*self.hoursInA_Day*60)),0)\n",
    "                    userSelltc += np.where(tempuserSell>1e-6,tempuserSell*self.regulator.marketPrice*(-self.PTCs)-\n",
    "                                                            (self.regulator.marketPrice*(-self.PTCs)*self.AR*(tempuserSell/self.AR)**2/(2*self.hoursInA_Day*60))-self.FTCs,0)\n",
    "                else:\n",
    "                    userSell += np.where(tempuserSell>1e-6,tempuserSell*self.regulator.marketPrice*(1),0)\n",
    "                    userSelltc += np.where(tempuserSell>1e-6,tempuserSell*self.regulator.marketPrice*(-self.PTCs)-self.FTCs,0)\n",
    "        \n",
    "        # regulator updates balance\n",
    "        self.usertradedf['buy'] = buyvec\n",
    "        self.usertradedf['sell'] = sellvec\n",
    "        self.tokentradedf['sell'] = sellamount\n",
    "        self.tokentradedf['buy'] = buyamount\n",
    "\n",
    "        self.users.update_arrival(actualArrival)\n",
    "        self.flowdf.iloc[self.currday*self.numOfusers: (self.currday+1)*self.numOfusers, 0] = np.maximum(self.users.predayDeparture-beginTime,-1)\n",
    "        self.flowdf.iloc[self.currday*self.numOfusers:(self.currday+1)*self.numOfusers, 1] = np.maximum(actualArrival-beginTime,-1)\n",
    "        if self.currday>=1:\n",
    "            mask1 = self.flowdf.iloc[self.currday*self.numOfusers:(self.currday+1)*self.numOfusers,0].values>0\n",
    "            mask2 = self.flowdf.iloc[(self.currday-1)*self.numOfusers:(self.currday)*self.numOfusers,0].values>0\n",
    "            self.flowconvergevec.append(np.linalg.norm(self.flowdf.iloc[self.currday*self.numOfusers:(self.currday+1)*self.numOfusers,0].values[mask1&mask2]-self.flowdf.iloc[(self.currday-1)*self.numOfusers:(self.currday)*self.numOfusers,0].values[mask1&mask2]))\n",
    "        self.flowdf['tt'] = np.where(self.flowdf.departure!=-1,self.flowdf.arrival-self.flowdf.departure, self.users.pttt)\n",
    "\n",
    "        # day to day learning\n",
    "        # update regulator account balance at the end of day\n",
    "        self.userSell = userSell\n",
    "        self.userSelltc = userSelltc\n",
    "        self.userBuytc = userBuytc\n",
    "        self.userToll = userToll\n",
    "\n",
    "        if self.scenario == 'Trinity':\n",
    "            # update regulator balance\n",
    "            self.userBuy = userBuy\n",
    "            self.regulator.update_balance(self.userBuy+self.userBuytc, self.userSell+self.userSelltc)\n",
    "        else:\n",
    "            self.userBuy = userToll\n",
    "            self.regulator.update_balance(userToll, self.users.distribution)\n",
    "        \n",
    "        self.pricevec.append(self.regulator.marketPrice)\n",
    "        self.ptsharevec.append(len(self.users.ptshare))\n",
    "        self.swvec.append(self.calculate_sw())\n",
    "\n",
    "        market_price = self.regulator.marketPrice\n",
    "        pt_share_number = self.users.ptshare\n",
    "        sw = self.calculate_sw()\n",
    "\n",
    "        if self.unusual['unusual'] and self.currday == self.unusual['day']:\n",
    "            self.users.d2d()\n",
    "            self.regulator.marketPrice = self.originalAtt['price']\n",
    "        else:\n",
    "            # d2d learnining\n",
    "            self.users.d2d()\n",
    "            if self.scenario == 'Trinity':\n",
    "                # update token price\n",
    "                self.regulator.update_price()\t\n",
    "\n",
    "        self.presellAfterdep = sellTime>self.users.predayDeparture\n",
    "\n",
    "        # TODO: replace self.toll with sum(trip_len * toll_profile * price), token_price\n",
    "        state_ls = [average_accumulation, average_tt, buyamount, sellamount]\n",
    "        state = np.concatenate(state_ls)\n",
    "        # aggravate the state from 1 min to 5 min\n",
    "        encode_step = state_aggravate\n",
    "        encode_shape = int(self.hoursInA_Day*60/encode_step)\n",
    "        state_encode = np.zeros(shape = encode_shape * len(state_ls))\n",
    "\n",
    "        for j in range(encode_shape):\n",
    "            state_encode[j] = np.mean(average_accumulation[j*5:(j+1)*5])\n",
    "            state_encode[j+encode_shape] = np.mean(average_tt[j*5:(j+1)*5])\n",
    "            state_encode[j+2*encode_shape] = np.mean(sellvec[j*5:(j+1)*5])\n",
    "            state_encode[j+3*encode_shape] = np.mean(buyvec[j*5:(j+1)*5])\n",
    "        return state_encode, vehicle_information, market_price, pt_share_number, sw\n",
    "    \n",
    "    # calculate social welfare value\n",
    "    def calculate_sw(self):\n",
    "        TT = np.where(self.users.predayDeparture!=-1, self.users.actualArrival-self.users.predayDeparture, self.users.pttt) \n",
    "        SDE = np.where(self.users.predayDeparture!=-1, np.maximum(0, self.users.desiredArrival+self.currday*self.hoursInA_Day*60-self.users.actualArrival), 0)\n",
    "        SDL = np.where(self.users.predayDeparture!=-1, np.maximum(0, self.users.actualArrival-(self.users.desiredArrival+self.currday*self.hoursInA_Day*60)), 0)\n",
    "        allowance = self.users.distribution\n",
    "        # either car fuel cost or transit fare\n",
    "        fuelcost = np.where(self.users.predayDeparture!=-1,self.users.dist/self.users.mpg*self.users.fuelprice ,self.users.ptfare)\n",
    "        ASC = np.zeros(self.numOfusers)\n",
    "        ptwaitingtime = np.where(self.users.predayDeparture!=-1,0 ,self.users.ptheadway)\n",
    "        util = ASC + (-2 * self.users.vot * TT - self.users.sde * SDE - self.users.sdl * SDL - self.users.waiting * ptwaitingtime\n",
    "             + self.user_params['lambda'] * np.log(self.user_params['gamma'] + self.users.I - 2 * self.userBuy + 2 * self.userSell + 2 * allowance - 2 * fuelcost)\n",
    "             + self.users.I - 2 * self.userBuy + 2 * self.userSell + 2 * allowance - 2 * fuelcost) + self.users.predayEps\n",
    "        NTMUI = 1 + self.user_params['lambda']/(self.user_params['gamma'] + self.users.I) # no toll marginal utility\n",
    "        if self.scenario == 'NT':\n",
    "            obj = np.sum(util)\n",
    "        else:\n",
    "            NT_util = np.load(\"./output/MFD/NT/NT_util.npy\")\n",
    "            # TODO: userBenefits = (util - NT_util)/NTMUI\n",
    "            userBenefits = (util - NT_util)\n",
    "            obj = np.sum(userBenefits) + 2 * self.regulator.RR\n",
    "        return obj\n",
    "\n",
    "    def aggdfbyTbyI(self,predayDeparture):\n",
    "        df = pd.DataFrame({'departure':np.where(predayDeparture!=-1,np.mod(predayDeparture,self.hoursInA_Day*60),predayDeparture),'dailyincome':self.users.I})\n",
    "        incinterval = np.zeros(6)\n",
    "        incinterval[1] = df.dailyincome.quantile(0.25)\n",
    "        incinterval[2] = df.dailyincome.quantile(0.5)\n",
    "        incinterval[3] = df.dailyincome.quantile(0.75)\n",
    "        incinterval[4] = df.dailyincome.quantile(0.9)\n",
    "        incinterval[5] = math.inf\n",
    "        df['Irange'] = pd.cut(df[\"dailyincome\"],incinterval)\n",
    "        \n",
    "        # only works for step toll\n",
    "        timeinterval = np.zeros(9)\n",
    "        timeinterval[0] = -1000\n",
    "        timeinterval[2:8] = self.tollparams[5:]\n",
    "        timeinterval[8] = self.hoursInA_Day*60\n",
    "        df['Trange'] = pd.cut(df[\"departure\"],timeinterval)\n",
    "        res = df.groupby(['Trange','Irange'],as_index=False).departure.count()\n",
    "        res['departure'].fillna(0,inplace=True)\n",
    "        res['Trange'] = res['Trange'].astype(str)\n",
    "        return res\n",
    "    \n",
    "    def numbytimebyinc(self,df,tval = '(380.0, 425.0]'):\n",
    "        tol = np.sum(df[df['Trange']==tval]['departure'])\n",
    "        byI = []\n",
    "        for i in pd.unique(df['Irange']):\n",
    "            byI.append(np.sum(df[(df['Trange']==tval)&(df['Irange']==i)]['departure']))\n",
    "        return byI\n",
    "    \n",
    "    def arcelasticity(self,d1,d2,c1,c2):\n",
    "        perd = (d2-d1)/((d1+d2)/2)\n",
    "        perc = (c2-c1)/((c1+c2)/2)\n",
    "        return perd/perc\n",
    "    \n",
    "    def demand_dist(self,predayDeparture1,predayDeparture2,p1,p2,tval='(420.0, 480.0]'):\n",
    "        print(\"p1:\",p1,\"p2:\",p2)\n",
    "        demand1 = self.aggdfbyTbyI(predayDeparture1)\n",
    "        demand2 = self.aggdfbyTbyI(predayDeparture2)\n",
    "        numbytval1 = self.numbytimebyinc(demand1,tval = tval)\n",
    "        numbytval2 = self.numbytimebyinc(demand2,tval = tval)\n",
    "        elas = []\n",
    "        for i in range(len(numbytval1)):\n",
    "            elas.append(self.arcelasticity(numbytval1[i],numbytval2[i],p1,p2))\n",
    "        print(\"travel share by I before:\", numbytval1)\n",
    "        print(\"travel share by I after:\", numbytval2)\n",
    "        print(\"peak arc elasticity by income: \", elas)\n",
    "        print(\"peak arc elasticity tol: \",self.arcelasticity(sum(numbytval1),sum(numbytval2),p1,p2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RunningMeanStd:\n",
    "    # Dynamically calculate mean and std\n",
    "    def __init__(self, shape):  # shape:the dimension of input data\n",
    "        self.n = 0\n",
    "        self.mean = np.zeros(shape)\n",
    "        self.S = np.zeros(shape)\n",
    "        self.std = np.sqrt(self.S)\n",
    "\n",
    "    def update(self, x):\n",
    "        x = np.array(x)\n",
    "        self.n += 1\n",
    "        if self.n == 1:\n",
    "            self.mean = x\n",
    "            self.std = x\n",
    "        else:\n",
    "            old_mean = self.mean.copy()\n",
    "            self.mean = old_mean + (x - old_mean) / self.n\n",
    "            self.S = self.S + (x - old_mean) * (x - self.mean)\n",
    "            self.std = np.sqrt(self.S / self.n )\n",
    "\n",
    "class Normalization:\n",
    "    def __init__(self, shape):\n",
    "        self.running_ms = RunningMeanStd(shape)\n",
    "\n",
    "    def update(self, x, update=True):\n",
    "        # Whether to update the mean and std,during the evaluating,update=Flase\n",
    "        if update:  \n",
    "            self.running_ms.update(x)\n",
    "        x = (x - self.running_ms.mean) / (self.running_ms.std + 1e-8)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class CommuteEnv(gym.Env): # env reset for each training/testing\n",
    "        # Define initial parameters for the environment\n",
    "    def __init__(self, simulation_day_num = 30, save_episode_freq = 10, train=True, save_dir = \"./train_result/\", space_shape=(4, int(12*60/5)) ):\n",
    "        super().__init__()\n",
    "        self.params = {'alpha':1.1, 'omega':0.9, 'theta':5*10**(-1), 'tao':90, 'Number_of_user':3700 } # alpha is unused\n",
    "        # define action space for each actionable value\n",
    "        # mu, sigma, A\n",
    "        self.space_shape = space_shape\n",
    "        self.action_space =  spaces.Box(low=np.array([-1.0, -1.0, -1.0]), high=np.array([1.0, 1.0, 1.0]), shape=(3,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low= -1,high= 1,\\\n",
    "                                                shape=space_shape, dtype=np.float32) # include more observations for a broader observation space\n",
    "        # self.seed_value = random.randint(0, 99999)\n",
    "        # self.sim = Simulation(_numOfdays=simulation_day_num, _user_params = user_params,\n",
    "        #                 _scenario=scenario,_allowance=allowance, \n",
    "        #                 _marketPrice=marketPrice, _allocation = allocation,\n",
    "        #                 _deltaP = deltaP, _numOfusers=numOfusers, _RBTD = RBTD, _Tstep=Tstep, \n",
    "        #                 _Plot = Plot, _seed = self.seed_value, _verbose = verbose, \n",
    "        #                 _unusual = unusual, _storeTT=storeTT, _CV=CV, save_dfname='NT')\n",
    "        self.render_mode = False\n",
    "\n",
    "        self.tt_eps = [] # daily average travel time\n",
    "        self.sw_eps = [] # social welfare\n",
    "        self.mp_eps = [] # market price\n",
    "        self.rw_eps = [] # step reward\n",
    "        self.action_eps = [] # action change\n",
    "        self.toll_eps = [] # toll profile\n",
    "\n",
    "        self.save_episode_freq = save_episode_freq\n",
    "        self.train = train\n",
    "        # self.norm = Normalization(space_shape)\n",
    "\n",
    "        self.tt_all_eps = [] # in all episodes\n",
    "        self.sw_all_eps = [] # in all episodes\n",
    "        self.mp_all_eps = [] \n",
    "        self.rw_all_eps = []\n",
    "        self.action_all_eps = []\n",
    "        self.toll_all_eps = []\n",
    "        self.price_all_eps = []\n",
    "\n",
    "        self.first_ep = True\n",
    "        self.day = 0\n",
    "\n",
    "        self.episode = 0 \n",
    "        self.first_episode = True\n",
    "\n",
    "        self.simulation_day_num = simulation_day_num \n",
    "        self.save_dir = save_dir\n",
    "        self.num_envs = 1\n",
    "        self.done = None\n",
    "        self.info = {}\n",
    "\n",
    "    # This method generates a new starting state often with some randomness \n",
    "    # to ensure that the agent explores the state space and learns a generalised policy \n",
    "    # about the environment.   \n",
    "    def reset(self, seed=  random.randint(0, 99999)): # env reset for each episode\n",
    "        super().reset(seed=seed)\n",
    "        if not self.first_episode: \n",
    "            self.episode +=1\n",
    "        self.first_episode = False\n",
    "        print(\" self.episode \", self.episode)\n",
    "        print(\"seed value \", seed)\n",
    "        self.set_seed(seed)\n",
    "        info = {}\n",
    "        # reset toll\n",
    "        self.toll_mu = random.random()*2 -1 # \n",
    "        self.toll_sigma = random.random()*2 -1 # \n",
    "        self.toll_A = random.random()*2 -1 # \n",
    "        \n",
    "        self.tt_eps = [] # daily average travel time\n",
    "        self.sw_eps = [] # social welfare\n",
    "        self.mp_eps = [] # market price\n",
    "        self.rw_eps = [] # step reward\n",
    "        self.action_eps = [] # action toll profile\n",
    "        self.price_eps = [] # token price\n",
    "        self.toll_eps = []\n",
    "\n",
    "        self.sim = Simulation(_numOfdays= self.simulation_day_num, _user_params = user_params,\n",
    "                            _scenario=scenario,_allowance=allowance, \n",
    "                            _marketPrice=marketPrice, _allocation = allocation,\n",
    "                            _deltaP = deltaP, _numOfusers=numOfusers, _RBTD = RBTD, _Tstep=Tstep, \n",
    "                            _Plot = Plot, _seed = self.seed_value, _verbose = verbose, \n",
    "                            _unusual = unusual, _storeTT=storeTT, _CV=CV, save_dfname='NT')\n",
    "        \n",
    "        observation = np.zeros(self.space_shape)\n",
    "        self.day = 0\n",
    "\n",
    "        return observation, info \n",
    "    \n",
    "    def step(self, action):\n",
    "        action = action\n",
    "        if 120*(self.toll_mu+action[0])+420< 300:\n",
    "            self.toll_mu = -1\n",
    "        elif 120*(self.toll_mu+action[0])+420> 540:\n",
    "            self.toll_mu = 1\n",
    "        else:\n",
    "            self.toll_mu+=action[0]\n",
    "\n",
    "        # 50, 70\n",
    "        if 10*(self.toll_sigma+action[1])+60 < 50:\n",
    "            self.toll_sigma = -1\n",
    "        elif 10*(self.toll_sigma+action[1])+60 > 70:\n",
    "            self.toll_sigma = 1\n",
    "        else:\n",
    "            self.toll_sigma+=action[1]\n",
    "        \n",
    "        if 2*(self.toll_A+action[2]) + 3 < 1:\n",
    "            self.toll_A = -1\n",
    "        elif 2*(self.toll_A+action[2]) + 3 > 5:\n",
    "            self.toll_A = 1\n",
    "        else:\n",
    "            self.toll_A += action[2]\n",
    "\n",
    "        tollparameters = np.array([120*self.toll_mu+420, 10*self.toll_sigma+60, 2*self.toll_A+3])\n",
    "        state_encode, vehicle_information, market_price, pt_share_number, sw  = self.sim.RL_simulateOneday(tollparameters, self.day, state_aggravate) # 5 days social welfare\n",
    "        observation = state_encode.reshape(self.space_shape)\n",
    "        observation = self.norm.update(observation, update=True)\n",
    "        # print(\"observation \", observation)\n",
    "        # TSTT = np.sum(vehicle_information[\"t_exp\"]) # total system travel time per day is 30000\n",
    "        # reward = 500000 - TSTT \n",
    "        ASTT = np.mean(vehicle_information[\"t_exp\"]) # average system travel time per day is 34min, 31min\n",
    "        reward = 80 - 2*ASTT \n",
    "        # print(np.save(\"tmp.npy\", vehicle_information[\"t_exp\"]))\n",
    "        # print(\"ASTT \", ASTT)\n",
    "        self.action_eps.append([action[0], action[1], action[2]])\n",
    "        self.toll_eps.append(tollparameters)\n",
    "        self.rw_eps.append(reward)\n",
    "        self.sw_eps.append(sw)\n",
    "        self.mp_eps.append(market_price)\n",
    "        self.tt_eps.append(np.mean(vehicle_information[\"t_exp\"]))\n",
    "        self.price_eps.append(self.sim.regulator.marketPrice)\n",
    "\n",
    "        info = {}\n",
    "        # if it is the last step in the episode\n",
    "        if self.day == self.simulation_day_num-1:\n",
    "            self.done = True\n",
    "            self.tt_all_eps.append(np.array(self.tt_eps))\n",
    "            self.sw_all_eps.append(np.array(self.sw_eps))\n",
    "            self.mp_all_eps.append(np.array(self.mp_eps))\n",
    "            self.rw_all_eps.append(np.array(self.rw_eps))\n",
    "            self.action_all_eps.append(np.array(self.action_eps))\n",
    "            self.toll_all_eps.append(np.array(self.toll_eps))\n",
    "            self.price_all_eps.append(np.array(self.price_eps))\n",
    "\n",
    "            if  (self.episode+1)% self.save_episode_freq == 0:\n",
    "                if self.train: \n",
    "                    save_dir = self.save_dir+\"/train_result/\"\n",
    "                else: \n",
    "                    save_dir = self.save_dir+\"/test_result/\"\n",
    "                isExist = os.path.exists(save_dir)\n",
    "                if not isExist:\n",
    "                    os.makedirs(save_dir)\n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_toll.npy\"), self.get_toll())\n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_tt.npy\"), self.get_tt())\n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_sw.npy\"), self.get_sw())\n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_mp.npy\"), self.get_mp())\n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_rw.npy\"), self.get_rw())\n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_action.npy\"), self.get_action())    \n",
    "                np.save((save_dir+str(self.episode+1)+\"_ppo_price.npy\"), self.get_price())    \n",
    "                self.sim.flowdf.to_csv((save_dir+\"flowdf.csv\"))\n",
    "                self.sim.tokentradedf.to_csv(save_dir+\"tokentradedf.csv\")\n",
    "                self.sim.usertradedf.to_csv(save_dir+\"usertradedf.csv\")            \n",
    "        else:\n",
    "            self.done = False\n",
    "\n",
    "        self.day += 1\n",
    "\n",
    "        return observation, reward, self.done, info\n",
    "    \n",
    "    def set_seed(self, seed_value): \n",
    "        random.seed(seed_value)                  \n",
    "        np.random.seed(seed_value)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "        torch.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        self.seed_value = seed_value\n",
    "\n",
    "        # defining functions to get statistics from environment\n",
    "    def get_day(self):\n",
    "        return self.day\n",
    "\n",
    "    def get_tt(self):\n",
    "        return np.array(self.tt_all_eps)\n",
    "\n",
    "    def get_sw(self):\n",
    "        return np.array(self.sw_all_eps)\n",
    "\n",
    "    def get_mp(self): # get market price\n",
    "        return np.array(self.mp_all_eps)\n",
    "\n",
    "    def get_rw(self): # get pt user number\n",
    "        # print(\" self.rw_all_eps \", self.rw_all_eps)\n",
    "        return np.array(self.rw_all_eps)\n",
    "\n",
    "    def get_action(self): # get pt user number\n",
    "        # print(\" self.rw_all_eps \", self.rw_all_eps)\n",
    "        return np.array(self.action_all_eps)\n",
    "    \n",
    "    def get_toll(self): # get pt user number\n",
    "        # print(\" self.rw_all_eps \", self.rw_all_eps)\n",
    "        return np.array(self.toll_all_eps)\n",
    "\n",
    "    def get_price(self): # get pt user number\n",
    "        # print(\" self.rw_all_eps \", self.rw_all_eps)\n",
    "        return np.array(self.price_all_eps)\n",
    "\n",
    "    def set_capacity(self, cap):\n",
    "        self.sim.set_capacity(cap)\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def _get_info(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_episode = 300\n",
    "simulation_day_num = 30 # the simulation days in one iteration \n",
    "train_time_steps = int(simulation_day_num * train_episode)# total train times\n",
    "evaluation_time_episode = 30 # evaluation times\n",
    "save_episode_train = 10 # the episode number to save train results\n",
    "save_episode_test = evaluation_time_episode\n",
    "save_dir = \"./results/PPO_\"+time.asctime(time.localtime(start_time))\n",
    "isExist = os.path.exists(save_dir)\n",
    "if not isExist:\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "env = CommuteEnv(simulation_day_num = simulation_day_num, save_episode_freq = save_episode_train, train = True, save_dir = save_dir, space_shape = (4, int(12*60/5)))\n",
    "# env = VecNormalize(env)\n",
    "# env.step()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = CheckpointCallback(save_freq= int(save_episode_train*30), save_path=(save_dir+\"/logs/\"), name_prefix=\"PPO\")\n",
    "\n",
    "# save_freq is the save frequency steps\n",
    "print(\" \")\n",
    "print(\"finish training!!!!!!!!!!!!!!!!!\")\n",
    "print(\" \")\n",
    "\n",
    "print(\" Start testing with total eps: \", evaluation_time_episode)\n",
    "simulation_day_num = simulation_day_num\n",
    "env = CommuteEnv(simulation_day_num = simulation_day_num, save_episode_freq = save_episode_test, train = False, save_dir = save_dir, space_shape = (4, int(12*60/5)))\n",
    "for i in range(evaluation_time_episode):\n",
    "    seed_value = random.randint(0, 99999999)\n",
    "    print(seed_value)\n",
    "    env.set_seed(seed_value) #every episode need to reset env and reset the seed\n",
    "    done  = False\n",
    "    obs = env.reset() \n",
    "    while not done:  # every step has same seed\n",
    "        action = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action[0])\n",
    "print(\"finish test¡ng!!!!!!!!!!!!!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
